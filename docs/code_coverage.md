# Remote, Daemon, sudo test coverage

## official docs

https://github.com/taiki-e/cargo-llvm-cov

## background

We cannot use tarpaulin because

1) it does not have support for subprocess/external profiling
2) it does not run on arm

we can't just run the direct llvm-cov because that

1) doesn't start fpgad or build it with the right flags
2) requires running cargo with sudo (bad)

Instead, we need to use `llvm-cov` to assemble a report from separate profiles generated by each test stream, and
cross-reference that with the binaries we ran. These binaries need to expose `llvm` coverage information so we need to
build them with special flags.

## dependencies

I think you only need

```
cargo install cargo-llvm-cov
```

and then on first run it prompts you to install the `llvm-tools-preview` component:

```shell
$ cargo llvm-cov
info: cargo-llvm-cov currently setting cfg(coverage); you can opt-out it by passing --no-cfg-coverage
I will run `rustup component add llvm-tools-preview --toolchain stable-x86_64-unknown-linux-gnu` to install the `llvm-tools-preview` component for the selected toolchain.
Proceed? [Y/n] y
info: downloading component 'llvm-tools'
info: installing component 'llvm-tools'
```

I can't remember for certain, but I think it also prompted me to manually install `pkg-config` and `libssl-dev`, however
one or both of these might only have been needed for tarpaulin.

```

sudo apt install pkg-config libssl-dev

```

but that might have been for tarpaulin...

## build

It's best to clean the target directories so that the `.profraw` files are generated during build. Use `cargo clean` and
`rm -rf <prefix>/llvm-cov-target/*` (adjust `<prefix>/llvm-cov-target/*` as necessary) or delete all final binaries and
test binaries from the target directory.

you can build your fpgad binary with

```shell
RUSTFLAGS="-C instrument-coverage -C llvm-args=-runtime-counter-relocation" cargo build
```

where `llvm-args=-runtime-counter-relocation` is necessary to enable the "continuous" generation of profile data.
By default, this `.profraw` file is only generated after exit(0).
We cannot exit(0) safely without implementing code that is not needed for fpgad except for code coverage so continuous
is a bypass.

The test binaries do not need this additional flag so they can be built by

```shell
RUSTFLAGS="-C instrument-coverage" cargo test --no-run
```

which will generate a bunch of `*.profraw` files in the source directory. The name of these can be specified by setting
the env var such as `LLVM_PROFILE_FILE="../target/llvm-cov-target/buildtime-%p-%m.profraw"` or similar.

We need to keep track of the test binary names.
I will refer to them as `<name>-...` throughout this doc so know that the `...` will be something like
`e84ef6b50b688299` in reality and each test binary has a different hash, and this hash changes on rebuild but the old
version does not get deleted.

To save time, you can build the binaries and test binaries at the same time with the same flags by doing

```shell
LLVM_PROFILE_FILE="../target/llvm-cov-target/build-%p-%m.profraw" RUSTFLAGS="-C instrument-coverage -C llvm-args=-runtime-counter-relocation" cargo test --no-run
```

For my situation, working on the kria and using RustRover remote build to sync files, I need to do

```shell
export CARGO_TARGET_DIR=../target
```

beforehand.

Building with these arguments generates a lot of `default_<numbers>.profraw` files in the source dir. These are the unit
test coverage files

This `CARGO_TARGET_DIR` determines how we create a test report from the individual profile files. If it is unspecified
then `llvm-cov` will search in `./target/llvm-cov-target/[debug/]` for binaries and profile files, else it will look in
`${CARGO_TARGET_DIR}/llvm-cov-target/[debug/]`.

To generate the raw profiles, we need to run the binaries with special environment variables, once again. To check that
we have built the binaries correctly we can check for llvm sections e.g.

```shell
$ readelf -S <binary> | grep llvm
  [17] __llvm_prf_names  PROGBITS         0000000000706eba  00706eba
  [29] __llvm_prf_cnts   PROGBITS         0000000000931018  00921018
  [30] __llvm_prf_data   PROGBITS         0000000000995790  00985790
  [31] __llvm_prf_vnds   PROGBITS         0000000000b2e750  00b1e750
  [34] __llvm_covfun     PROGBITS         0000000000000000  00b247c0
  [35] __llvm_covmap     PROGBITS         0000000000000000  00e48aa8
```

## moving stuff around

as mentioned, the target dir for the profiles etc is in a dir called `llvm-cov-target` so let's gather what we need in
there.
We need to copy/move the fpgad binary itself and all test binaries into `${CARGO_TARGET_DIR}/llvm-cov-target/debug/` (
and rename them to remove the hash if you like)
e.g:

```shell
mkdir -p ../target/llvm-cov-target/debug/
cp ../target/debug/fpgad ../target/llvm-cov-target/debug/fpgad
cp ../target/debug/deps/cli-... ../target/llvm-cov-target/debug/test_cli  
cp ../target/debug/deps/fpgad-... ../target/llvm-cov-target/debug/test_fpgad  
cp ../target/debug/deps/universal-... ../target/llvm-cov-target/debug/test_universal 
cp ../target/debug/deps/fpgad_macros-... ../target/llvm-cov-target/debug/test_fpgad_macros  
```

and to save moving around, we want to spawn the resulting profiles in `${CARGO_TARGET_DIR}/llvm-cov-target/` (up one dir
from the binaries). To do this, we can specify the output path for the profile files using the `LLVM_PROFILE_FILE` env
var when running the binary i.e.
`LLVM_PROFILE_FILE="<path>/<filename>-<flags>.<extension>" <binary>`
see the run section for more.

## run

When running the binaries, if `LLVM_PROFILE_FILE` is set, the file is inspected for flags and then the profiling
behavior is determined from these. In our case, we want to run fpgad with `%c` flag, and add any available flags as you
see fit e.g. `-%p` to substitutes for the process ID (
see [the clang llvm docs](https://clang.llvm.org/docs/SourceBasedCodeCoverage.html#id4) for more on flags). In our case,
we want %c for fpgad, and no special flags for the test binaries.
If we stay in the source dir, we can run fpgad in one terminal (or in the background) via

```shell
sudo env RUST_LOG=trace LLVM_PROFILE_FILE="../target/llvm-cov-target/fpgad-%p%c.profraw" ../target/llvm-cov-target/debug/fpgad
```

to start the daemon and start gathering profile information in `../target/llvm-cov-target/fpgad.profraw`
then we can run each of our test executables with and without sudo as necessary:

```shell
sudo LLVM_PROFILE_FILE="../target/llvm-cov-target/test_cli-%p.profraw" ../target/llvm-cov-target/debug/test_cli  
sudo LLVM_PROFILE_FILE="../target/llvm-cov-target/test_fpgad-%p.profraw" ../target/llvm-cov-target/debug/test_fpgad  
sudo LLVM_PROFILE_FILE="../target/llvm-cov-target/test_universal-%p.profraw" ../target/llvm-cov-target/debug/test_universal --test-threads=1 # the single thread isolates each test IO environment
sudo LLVM_PROFILE_FILE="../target/llvm-cov-target/test_fpgad_macros-%p.profraw" ../target/llvm-cov-target/debug/test_fpgad_macros
```

and then we can stop `fpgad`.

## collect and process

Now that we have the collection of `.profraw` files, we can use llvm-cov to gather them up, cross-reference them with
the original binaries, and work out what lines of code were never run. To do this, from whatever directory contains the
top level `Cargo.toml` (where we have been for this entire doc), run

```shell
cargo llvm-cov report
```

to print the coverage report in the terminal (and pipe to file or whatever you want).

If you're not using ssh (using a window manager) you can run

```
cargo llvm-cov report --open
```

to generate and open an html report in your browser.

For other formats, specify the appropriate flag (and probably `--output-path` too ) i.e.

```shell
cargo llvm-cov report --json --output-path=coverage.json
cargo llvm-cov report --lcov --output-path=coverage.lcov
cargo llvm-cov report --html
```

If you do generate html output and want to copy it just do, for example

```shell
scp -r ubuntu@$KRIA:/home/ubuntu/fpgad/target/llvm-cov/html/* ./html
```

from the host system. Here, `$KRIA` is the IP address of the DUT, /home/ubuntu/fpgad/target is where `../target` from
the earlier steps points to, and `./html` is the host system destination. 